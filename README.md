# Benchmarking Robustness of Deep Learning Classifiers Using Two-Factor Perturbation
This paper adds to the fundamental body of work on benchmarking the robustness of deep learning (DL) classifiers. We introduce a new two-dimensional benchmarking matrix to evaluate robustness of DL classifiers, and we innovate a four-quadrant statistical visualization tool, including minimum accuracy, maximum accuracy, mean accuracy, and coefficient of variation, for benchmarking robustness of DL classifiers. To measure robust DL classifiers, we create comprehensive 69 benchmarking image sets, including a clean set, sets with single factor perturbations, and sets with two-factor perturbation conditions. After collecting experimental results, we first report that using two-factor perturbed images improves both robustness and accuracy of DL classifiers. The two-factor perturbation includes (1) two digital perturbations (salt & pepper noise and Gaussian noise) applied in both sequences, and (2) one digital perturbation (salt & pepper noise) and a geometric perturbation (rotation) applied in both sequences. All source codes, related image sets, and preliminary data, figures are shared on an online website to support future academic research and industry projects. The online resources locate at https://github.com/caperock/robustai.
